{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_gpt3mix.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rCT49FJwzhB3"
      ]
    },
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXro9efVU84k"
      },
      "source": [
        "# üìà: Text Augmentation using large-scale LMs and prompt engineering\n",
        "\n",
        "This notebook looks into the possibility of performing data augmentation on an NLP dataset leveraging the few-shot capabilities of large-scale LMs and prompt engineering üí°\n",
        "\n",
        "Data augmentation techniques are used to generate additional samples. Data augmentation is already standard practice in computer vision projects üëå, but can also be leveraged in many NLP problems. We'll use a limited training set to simulate a real-world use case, where we are often constrained by the size of the available data ü§¶."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acwqGIAyU84m"
      },
      "source": [
        "## üõ†Ô∏è Getting started\n",
        "\n",
        "The cells below will setup everything that is required to get started with data augmentation and finetuning an NLP model with the HuggingFace API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buIDjl_wU84m"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-ItvjqP4Cxn"
      },
      "source": [
        "!pip install -q transformers datasets tokenizers openai requests sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir6zD__FU84n"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM-09Chsj7wI"
      },
      "source": [
        "import re\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from datasets import load_dataset, concatenate_datasets, load_from_disk, load_metric, Dataset\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, TrainerCallback, AutoModelForCausalLM, AutoModelForSeq2SeqLM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFQ6LEgjeRWb"
      },
      "source": [
        "### Download dataset\n",
        "We'll train and evaluate our models on [Emotion](https://huggingface.co/datasets/emotion) dataset that contains English Twitter messages labeled as one of the six basic emotions: anger, fear, joy, love, sadness and surprise. To reduce the complexity of the task, we will keep only three labels, namely:\n",
        "- joy üòÇ\n",
        "- anger üò†\n",
        "- surprise üòØ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ltsurmvaaGd"
      },
      "source": [
        "# load the dataset and filter on samples that have a token count less than 30 to use only short tweets\n",
        "max_input_len = 30\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "emotion_ds = load_dataset(\"emotion\").filter(lambda e: len(tokenizer.batch_encode_plus([e['text']]).input_ids[0]) < int(max_input_len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ24-mWS6elF"
      },
      "source": [
        "The dataset is already split into 16,000 train and 2,000 test samples. To investigate the effectiveness of the augmentation method, we will use only 10 samples per class as a train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YI6-pZdSqnI"
      },
      "source": [
        "# select 10 random train samples from each of the three emotions\n",
        "# sadness (0), joy (1), love (2), anger (3), fear (4), surprise (5)\n",
        "joy_train_samples = emotion_ds['train'].filter(lambda e: e['label'] == 1).select(range(10))\n",
        "anger_train_samples = emotion_ds['train'].filter(lambda e: e['label'] == 3).select(range(10))\n",
        "surprise_train_samples = emotion_ds['train'].filter(lambda e: e['label'] == 5).select(range(10))\n",
        "\n",
        "# map emotions to integers for labeling\n",
        "# joy (0), anger (1), surprise (2)\n",
        "def map_emotions(example):\n",
        "  if example['label'] == 1: # joy\n",
        "    example['label'] = 0\n",
        "  elif example['label'] == 3: # anger\n",
        "    example['label'] = 1\n",
        "  else: \n",
        "    example['label'] = 2 # surprise\n",
        "  return example\n",
        "\n",
        "# create a train set that consists of 10 samples per class and filter the test \n",
        "# set to contain only the valid labels\n",
        "emotion_train_ds = concatenate_datasets([joy_train_samples, anger_train_samples, surprise_train_samples]).map(lambda e: map_emotions(e)).shuffle(seed=42)\n",
        "emotion_test_ds = emotion_ds[\"test\"].filter(lambda e: e['label'] in [1, 3, 5]).map(lambda e: map_emotions(e))\n",
        "\n",
        "# define the maping between emotions and labels\n",
        "idx2label = {0: 'joy', 1: 'anger', 2: 'surprise'}\n",
        "label2idx = {'joy': 0, 'anger': 1, 'surprise': 2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi2XjbC69Of5"
      },
      "source": [
        "Before proceeding with the data augmentation, let's have a look into the baseline dataset üòé!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD2xmdrg9OLY",
        "outputId": "98d7d9be-9475-414e-a30b-122d9defa0f3"
      },
      "source": [
        "print(\"Train set\")\n",
        "print(\"Total samples: {}\\n\".format(len(emotion_train_ds)))\n",
        "print(\"A random sample\")\n",
        "print(\"Text: {} \\nLabel: {}\".format(emotion_train_ds['text'][10], idx2label[emotion_train_ds['label'][10]]))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Test set\")\n",
        "print(\"Total samples: {}\\n\".format(len(emotion_test_ds)))\n",
        "print(\"A random sample\")\n",
        "print(\"Text: {} \\nLabel: {}\".format(emotion_test_ds['text'][10], idx2label[emotion_test_ds['label'][10]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set\n",
            "Total samples: 30\n",
            "\n",
            "A random sample\n",
            "Text: i feel angered and firey \n",
            "Label: anger\n",
            "\n",
            "\n",
            "Test set\n",
            "Total samples: 797\n",
            "\n",
            "A random sample\n",
            "Text: i feel more virtuous than when i eat veggies dipped in hummus \n",
            "Label: joy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIJPd8P9S9kW"
      },
      "source": [
        "## Text Augmentation pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkx02t5Z3ZVN"
      },
      "source": [
        "We will leverage the few-shot capabilities of large LMs to generate synthetic but hyper-realistic samples from a mixture of real saples. Specifically, we select two real samples from our dataset and embed these samples in a carefully designed prompt. Then, the LM takes as input the prompt and generates an augmented mixed sample influenced by the sample sentences.\n",
        "\n",
        "\n",
        "Generallly, a prompt looks like this:\n",
        "\n",
        "    Each item in the following list contains a <text type> and the\n",
        "    respective <label type>. <label type> is one of ‚Äô<label token 1>‚Äô,\n",
        "    ..., or ‚Äô<label token N>‚Äô. \n",
        "    <text type>: <example text 1> (<label type>: <example label 1>)\n",
        "    ...\n",
        "    <text type>: <example text k> (<label type>: <example label k>)\n",
        "    <text type>:\n",
        "\n",
        "In our case the prompt looks like this:\n",
        "\n",
        "    Each item in the following list contains a tweet and the\n",
        "    respective sentiment. Sentiment is one of ‚Äôjoy‚Äô, 'surprise' or 'anger'. \n",
        "    Tweet: i feel angered and firey (Sentiment: anger)\n",
        "    Tweet: im feeling very peaceful about our wedding again now after having (Sentiment: joy)\n",
        "    Tweet:\n",
        "\n",
        "You can find more information on text augmentation using large LMs in [GPT3Mix](https://arxiv.org/abs/2104.08826) paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj2Of7vGILFJ"
      },
      "source": [
        "First, we should extract pairs of samples from the train set. There are various extraction strategies that can be used to increase the quality of the synthetic samples. We will simply extract the pairs randomly since by repeating random sampling a diverse synthetic dataset will be created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlI7GYwbGx5m"
      },
      "source": [
        "# define a function that returns two random samples from the train set.\n",
        "def get_random_samples():\n",
        "  s1 = random.randint(0, len(emotion_train_ds)-1)\n",
        "  s2 = random.randint(0, len(emotion_train_ds)-1)\n",
        "  return emotion_train_ds['text'][s1], emotion_train_ds['label'][s1], emotion_train_ds['text'][s2], emotion_train_ds['label'][s2]\n",
        "\n",
        "# define a function that takes as input two samples and generates the prompt\n",
        "# that we should pass to the GPT-3 language model for completion.\n",
        "def get_prompt(text1, label1, text2, label2):\n",
        "  description = \"Each item in the following list contains a tweet and the respective sentiment. Sentiment is one of 'joy', 'surprise' or 'anger'.\"\n",
        "  prompt = (f\"{description}\\n\"\n",
        "            f\"Tweet: {text1} (Sentiment: {idx2label[label1]})\\n\"\n",
        "            f\"Tweet: {text2} (Sentiment: {idx2label[label2]})\\n\"\n",
        "            f\"Tweet:\")\n",
        "  return prompt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9xNf9D4jY00"
      },
      "source": [
        "### GPT-3\n",
        "\n",
        "We will leverage [GPT-3](https://openai.com/blog/openai-api/) as our LM that is a powerful model developed by Open AI and an excellent few-shot learner allowing it to be controlled via natural text prompts. GPT-3 can be accessed through an API.\n",
        "\n",
        "We will generate 10, 50, 100 and 200 synthetic samples using GPT-3 to investigate the effectiveness of text augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAzLn9t83YCS"
      },
      "source": [
        "# define the number of synthetic samples to generate\n",
        "n = 10\n",
        "new_texts = []\n",
        "new_labels = []\n",
        "api_key =  # insert your api key for GPT-3\n",
        "headers = {'Authorization' : 'Bearer ' + api_key ,\n",
        "              'Content-type':'application/json', \n",
        "              'Accept':'application/json'}\n",
        "\n",
        "iter = 0\n",
        "while iter < n:\n",
        "  # select two random samples from training set\n",
        "  text1, label1, text2, label2 = get_random_samples()\n",
        "  # create the prompt\n",
        "  prompt = get_prompt(text1, label1, text2, label2)\n",
        "  # send a post request to gpt-3 using the prompt\n",
        "  response = requests.post('https://api.openai.com/v1/engines/davinci/completions', \n",
        "                           headers=headers,\n",
        "                           data = json.dumps({\"prompt\": prompt, \n",
        "                                              \"max_tokens\": 30,\n",
        "                                              \"temperature\": 0.9,\n",
        "                                              \"top_p\": 0.95}))\n",
        "\n",
        "  # get response and extract the generated text and label\n",
        "  # the generated output will be in the form \"<text> (Sentiment: <label>)\"\n",
        "  data = response.json()['choices'][0]['text'].split('\\n')[0].split('(Sentiment:')\n",
        "\n",
        "  if len(data) < 2:\n",
        "    # the format of the response is invalid\n",
        "    continue\n",
        "\n",
        "  text = data[0]\n",
        "  label = data[1].split(')')[0].strip()\n",
        "\n",
        "  if label not in ['joy', 'anger', 'surprise']:\n",
        "    # the format of the response is invalid\n",
        "    continue\n",
        "\n",
        "  new_texts.append(text)\n",
        "  new_labels.append(label2idx[label])\n",
        "  iter += 1\n",
        "\n",
        "# define the synthetic dataset and save it to disk so as to prevent sending \n",
        "# many api requests\n",
        "synthetic_ds = Dataset.from_dict({'text': new_texts, 'label': new_labels})\n",
        "synthetic_ds.save_to_disk('./drive/MyDrive/text_augmentation/gpt-3/10')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPlF7dXKor6v"
      },
      "source": [
        "# load the synthetic datasets with 10, 50, 100 and 200 samples\n",
        "# run this if the dataset has already been saved and set the path in your workspace\n",
        "synthetic_gpt3_10_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-3/10')\n",
        "synthetic_gpt3_50_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-3/50')\n",
        "synthetic_gpt3_100_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-3/100')\n",
        "synthetic_gpt3_200_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-3/200')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b4GsUwfINep"
      },
      "source": [
        "Now let's print some synthetic samples to examine their quality!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6irrOSPrKVU9",
        "outputId": "27825c0c-ea8f-4738-aec3-b7629b5aa6fc"
      },
      "source": [
        "print(\"Dataset of 10 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gpt3_10_ds['text'][5], idx2label[synthetic_gpt3_10_ds['label'][5]]))\n",
        "print(\"Dataset of 50 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gpt3_50_ds['text'][5], idx2label[synthetic_gpt3_50_ds['label'][5]]))\n",
        "print(\"Dataset of 100 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gpt3_100_ds['text'][5], idx2label[synthetic_gpt3_100_ds['label'][5]]))\n",
        "print(\"Dataset of 200 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gpt3_200_ds['text'][5], idx2label[synthetic_gpt3_200_ds['label'][5]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset of 10 synthetic samples:\n",
            "Text:  even if ur not into these kind of things u have to admit it's pretty cool  \n",
            "Label: joy\n",
            "\n",
            "Dataset of 50 synthetic samples:\n",
            "Text:  i want to stop running and walk...but the fact that i'm still running is the real miracle  \n",
            "Label: joy\n",
            "\n",
            "Dataset of 100 synthetic samples:\n",
            "Text:  i want a beer right now  \n",
            "Label: anger\n",
            "\n",
            "Dataset of 200 synthetic samples:\n",
            "Text:  lol owls  \n",
            "Label: joy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6dLc7xMK0NJ"
      },
      "source": [
        "We see that GPT-3 has effectively generated very realistic samples. üëèüëèüëè"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5alF-lekkIr"
      },
      "source": [
        "### GPT-J\n",
        "\n",
        "As an open-source alternative of GPT-3, we can use [GPT-J](https://6b.eleuther.ai/) that is a 6 billion parameter model released by a group called Eleuther AI. The goal of the group is to democratize huge LMs, so they released GPT-J and it is currently publicly available. GPT-3 on the other hand, which was released by openAI has 175 billion parameters and is not openly available at the time.\n",
        "\n",
        "To use GPT-J, we can simply load it through HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ5c63s8zMeR"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7QKbaaekqCr"
      },
      "source": [
        "# define the number of synthetic samples to generate\n",
        "n = 10\n",
        "new_texts = []\n",
        "new_labels = []\n",
        "\n",
        "iter = 0\n",
        "while iter < n:\n",
        "  # select two random samples from training set\n",
        "  text1, label1, text2, label2 = get_random_samples()\n",
        "  # create the prompt\n",
        "  prompt = get_prompt(text1, label1, text2, label2)\n",
        "\n",
        "  # generate text using GPT-J model\n",
        "  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "  gen_tokens = model.generate(input_ids, do_sample=True, temperature=0.9, max_length=100,)\n",
        "  gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  # the generated output will be in the form \"<text> (Sentiment: <label>)\"\n",
        "  data = gen_text.split('\\n')[3].strip('Tweet: ').split('(Sentiment:')\n",
        "  if len(data) < 2:\n",
        "    # the format of the response is invalid\n",
        "    continue\n",
        "\n",
        "  text = data[0]\n",
        "  label = data[1].split(')')[0].strip()\n",
        "  if label not in ['joy', 'anger', 'surprise']:\n",
        "    # the format of the response is invalid\n",
        "    continue\n",
        "\n",
        "  new_texts.append(text)\n",
        "  new_labels.append(label2idx[label])\n",
        "  iter += 1\n",
        "\n",
        "# define the synthetic dataset and save it to disk \n",
        "synthetic_ds = Dataset.from_dict({'text': new_texts, 'label': new_labels})\n",
        "synthetic_ds.save_to_disk('./drive/MyDrive/text_augmentation/gpt-j/10')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu0JVPbQk1zB"
      },
      "source": [
        "synthetic_gptj_10_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-j/10')\n",
        "synthetic_gptj_50_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-j/50')\n",
        "synthetic_gptj_100_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-j/100')\n",
        "synthetic_gptj_200_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-j/200')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpq3vNSMFWx_",
        "outputId": "e11f2b52-0d25-4684-b882-37fa1a0ea4bb"
      },
      "source": [
        "print(\"Dataset of 10 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gptj_10_ds['text'][5], idx2label[synthetic_gptj_10_ds['label'][5]]))\n",
        "print(\"Dataset of 50 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gptj_50_ds['text'][5], idx2label[synthetic_gptj_50_ds['label'][5]]))\n",
        "print(\"Dataset of 100 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gptj_100_ds['text'][5], idx2label[synthetic_gptj_100_ds['label'][5]]))\n",
        "print(\"Dataset of 200 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gptj_200_ds['text'][5], idx2label[synthetic_gptj_200_ds['label'][5]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset of 10 synthetic samples:\n",
            "Text: he didn't even call me back  \n",
            "Label: surprise\n",
            "\n",
            "Dataset of 50 synthetic samples:\n",
            "Text: i am feeling angry and sad at the same time  \n",
            "Label: anger\n",
            "\n",
            "Dataset of 100 synthetic samples:\n",
            "Text: i have the feeling she was amused and delighted  \n",
            "Label: joy\n",
            "\n",
            "Dataset of 200 synthetic samples:\n",
            "Text: how dare you?  \n",
            "Label: anger\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygrmMapNJrsg"
      },
      "source": [
        "Even though GPT-J is much smaller than GPT-3, it manages to generate high quality samples üëè."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PaeBV_AWb_-"
      },
      "source": [
        "### GPT-Neo\n",
        "\n",
        "A third alternative is GPT-Neo that is also released by Eleuther AI. It has 2.7 billion parameters and is also publicly available. \n",
        "\n",
        "Like GPT-J, we can access GPT-Neo through HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7_p-5lcF3vq"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-2.7B')\n",
        "model = AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-2.7B')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnYf0vZdHGiK"
      },
      "source": [
        "# define the number of synthetic samples to generate\n",
        "n = 10\n",
        "new_texts = []\n",
        "new_labels = []\n",
        "\n",
        "iter = 0\n",
        "while iter < n:\n",
        "  # select two random samples from training set\n",
        "  text1, label1, text2, label2 = get_random_samples()\n",
        "  # create the prompt\n",
        "  prompt = get_prompt(text1, label1, text2, label2)\n",
        "\n",
        "  # generate text using GPT-J model\n",
        "  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "  gen_tokens = model.generate(input_ids, do_sample=True, temperature=0.9, max_length=100,)\n",
        "  gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  # the generated output will be in the form \"<text> (Sentiment: <label>)\"\n",
        "  data = gen_text.split('\\n')[3].strip('Tweet: ').split('(Sentiment:')\n",
        "  if len(data) < 2:\n",
        "    # the format of the response is invalid\n",
        "    continue\n",
        "  print(data)\n",
        "  text = data[0]\n",
        "  label = data[1].split(')')[0].strip()\n",
        "  if label not in ['joy', 'anger', 'surprise']:\n",
        "    # the format of the response is invalid\n",
        "    continue\n",
        "\n",
        "  new_texts.append(text)\n",
        "  new_labels.append(label2idx[label])\n",
        "  iter += 1\n",
        "\n",
        "\n",
        "# define the synthetic dataset and save it to disk \n",
        "synthetic_ds = Dataset.from_dict({'text': new_texts, 'label': new_labels})\n",
        "synthetic_ds.save_to_disk('./drive/MyDrive/text_augmentation/gpt-neo/10')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MncjIfEcHRsM"
      },
      "source": [
        "synthetic_gptneo_10_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-neo/10')\n",
        "synthetic_gptneo_50_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-neo/50')\n",
        "synthetic_gptneo_100_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-neo/100')\n",
        "synthetic_gptneo_200_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-neo/200')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhdkFMCpHeuO",
        "outputId": "ccbe2f62-1b9a-49b1-c508-101e0bfe1516"
      },
      "source": [
        "print(\"Dataset of 10 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gptneo_10_ds['text'][5], idx2label[synthetic_gptneo_10_ds['label'][5]]))\n",
        "print(\"Dataset of 50 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gptneo_50_ds['text'][5], idx2label[synthetic_gptneo_50_ds['label'][5]]))\n",
        "print(\"Dataset of 100 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gptneo_100_ds['text'][5], idx2label[synthetic_gptneo_100_ds['label'][5]]))\n",
        "print(\"Dataset of 200 synthetic samples:\")\n",
        "print(\"Text: {} \\nLabel: {}\\n\".format(synthetic_gptneo_200_ds['text'][5], idx2label[synthetic_gptneo_200_ds['label'][5]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset of 10 synthetic samples:\n",
            "Text: hy do i feel bored when everyone is talking about something else  \n",
            "Label: anger\n",
            "\n",
            "Dataset of 50 synthetic samples:\n",
            "Text: I am happy to be here  \n",
            "Label: joy\n",
            "\n",
            "Dataset of 100 synthetic samples:\n",
            "Text: I feel disgusted!  \n",
            "Label: surprise\n",
            "\n",
            "Dataset of 200 synthetic samples:\n",
            "Text: i love my job and the people I work with  \n",
            "Label: joy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbMrIov5ON6M"
      },
      "source": [
        "GPT-Neo generates realistic samples! However, we can see that there are cases that the label is wrong (example 3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gesWuhM9jbLq"
      },
      "source": [
        "## üöÄ Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QaSNzfSTG4D"
      },
      "source": [
        "Here we define the model and the training pipeline. We will use [DistilBERT](https://arxiv.org/abs/1910.01108) that is a light Transformer trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT‚Äôs performances as measured on the GLUE language understanding benchmark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xqcEiJqBZsB"
      },
      "source": [
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "batch_size = 8\n",
        "max_size = 200 # size of the largest augmented dataset\n",
        "steps = 5*int(max_size/batch_size) # 5 epochs in the large dataset\n",
        "\n",
        "run_dicts = [] # list of dicts to store both metrics and logs for all the experiment runs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-q6U8DAx0Jp"
      },
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "        Calculates the accuracy of the model's predictions, calculated as follows; (TP + TN) / (TP + TN + FP + FN) with TP: True positive TN: True negative FP: False positive FN: False negative\n",
        "    \"\"\"\n",
        "\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels) \n",
        "\n",
        "\n",
        "class LogAccumulatorCallback(TrainerCallback):\n",
        "    \"\"\"\n",
        "    A class that stores both the training and the evaluation loss\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.acc_logs = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        _ = logs.pop(\"total_flos\", None)\n",
        "        if state.is_local_process_zero and ('loss' in logs or 'eval_loss' in logs):\n",
        "            self.acc_logs.append(logs.copy())\n",
        "\n",
        "\n",
        "def train_and_evaluate(train_ds, test_ds, identifier):\n",
        "    def tokenize(batch):\n",
        "        return tokenizer(batch['text'], padding=True, truncation=True)\n",
        "    \n",
        "    train_ds = train_ds.map(tokenize, batched=True, batch_size=len(train_ds), remove_columns=[\"text\"])\n",
        "    test_ds = test_ds.map(tokenize, batched=True, batch_size=len(test_ds), remove_columns=[\"text\"])\n",
        "    \n",
        "    training_args = TrainingArguments(\n",
        "        identifier,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        logging_strategy=\"steps\",\n",
        "        weight_decay=0.01,\n",
        "        learning_rate=1e-4,\n",
        "        max_steps=steps,\n",
        "        logging_steps=20\n",
        "    )\n",
        "    \n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)\n",
        "\n",
        "    # Partially freezing the weights of initial layers of the model\n",
        "    # Since we're working on small datasets as it usually reduces overfitting\n",
        "    # Another advantage of partial freezing is reduced memory usage and a speed improvement during training.\n",
        "    for block in model.distilbert.embeddings.modules():\n",
        "        for param in block.parameters():\n",
        "            param.requires_grad=False\n",
        "\n",
        "    for i in [0,1,2]:\n",
        "        for block in model.distilbert.transformer.layer[i].modules():\n",
        "            for param in block.parameters():\n",
        "                param.requires_grad=False\n",
        "\n",
        "            \n",
        "    logger = LogAccumulatorCallback()\n",
        "    trainer = Trainer(\n",
        "        model=model, args=training_args, \n",
        "        train_dataset=train_ds, \n",
        "        eval_dataset=test_ds,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[logger],\n",
        "    )\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    \n",
        "    return metrics, logger.acc_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIp57un2x7Qy",
        "outputId": "9254321f-4eb6-4cca-88d8-db0b6776db97"
      },
      "source": [
        "### Model baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mDmH_lwU84r"
      },
      "source": [
        "# train our model on the baseline dataset without augmentation\n",
        "metrics, logs = train_and_evaluate(emotion_train_ds, emotion_test_ds, \"baseline\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"baseline\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jge5A7tfo5Qp"
      },
      "source": [
        "### Model with augmented data of GPT-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zpt0ZyDU84s"
      },
      "source": [
        "# train our model on the augmented dataset that contains 10 extra synthetic samples.\n",
        "augmented_gpt3_10_ds = concatenate_datasets([emotion_train_ds, synthetic_gpt3_10_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gpt3_10_ds, emotion_test_ds, \"augmented_10\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gpt3_10\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD2fNj8kNa_t"
      },
      "source": [
        "# train our model on the augmented dataset that contains 50 extra synthetic samples.\n",
        "augmented_gpt3_50_ds = concatenate_datasets([emotion_train_ds, synthetic_gpt3_50_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gpt3_50_ds, emotion_test_ds, \"augmented_50\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gpt3_50\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8wBLo-6NbOf"
      },
      "source": [
        "# train our model on the augmented dataset that contains 100 extra synthetic samples.\n",
        "augmented_gpt3_100_ds = concatenate_datasets([emotion_train_ds, synthetic_gpt3_100_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gpt3_100_ds, emotion_test_ds, \"augmented_100\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gpt3_100\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuyqQtdRaus6"
      },
      "source": [
        "# train our model on the augmented dataset that contains 200 extra synthetic samples.\n",
        "augmented_gpt3_200_ds = concatenate_datasets([emotion_train_ds, synthetic_gpt3_200_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gpt3_200_ds, emotion_test_ds, \"augmented_200\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gpt3_200\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvuiZAQLzWhq"
      },
      "source": [
        "### Model with augmented data of GPT-J"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2Ds8dIwZqBc"
      },
      "source": [
        "# train our model on the dataset augmented by GPT-J that contains 10 extra synthetic samples.\n",
        "augmented_gptj_10_ds = concatenate_datasets([emotion_train_ds, synthetic_gptj_10_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gptj_10_ds, emotion_test_ds, \"augmented_gptj_10\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gptj_10\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvI_XA-jaqFn"
      },
      "source": [
        "# train our model on the dataset augmented by GPT-J that contains 50 extra synthetic samples.\n",
        "augmented_gptj_50_ds = concatenate_datasets([emotion_train_ds, synthetic_gptj_50_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gptj_50_ds, emotion_test_ds, \"augmented_gptj_50\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gptj_50\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2PdUxs1aqcG"
      },
      "source": [
        "# train our model on the dataset augmented by GPT-J that contains 100 extra synthetic samples.\n",
        "augmented_gptj_100_ds = concatenate_datasets([emotion_train_ds, synthetic_gptj_100_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gptj_100_ds, emotion_test_ds, \"augmented_gptj_100\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gptj_100\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17R1EgRPaKQp"
      },
      "source": [
        "# train our model on the dataset augmented by GPT-J that contains 200 extra synthetic samples.\n",
        "augmented_gptj_200_ds = concatenate_datasets([emotion_train_ds, synthetic_gptj_200_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gptj_200_ds, emotion_test_ds, \"augmented_gptj_200\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gptj_200\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcKYcXzaHsgQ"
      },
      "source": [
        "### Model with augmented data of GPT-Neo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eCuVHbNHuSd"
      },
      "source": [
        "# train our model on the dataset augmented by GPT-Neo that contains 10 extra synthetic samples.\n",
        "augmented_gptneo_10_ds = concatenate_datasets([emotion_train_ds, synthetic_gptneo_10_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gptneo_10_ds, emotion_test_ds, \"augmented_gptneo_10\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gptneo_10\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4VHA6IaHuhF"
      },
      "source": [
        "# train our model on the dataset augmented by GPT-Neo that contains 50 extra synthetic samples.\n",
        "augmented_gptneo_50_ds = concatenate_datasets([emotion_train_ds, synthetic_gptneo_50_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gptneo_50_ds, emotion_test_ds, \"augmented_gptneo_50\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gptneo_50\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mcgsV1hHuyQ"
      },
      "source": [
        "# train our model on the dataset augmented by GPT-Neo that contains 100 extra synthetic samples.\n",
        "augmented_gptneo_100_ds = concatenate_datasets([emotion_train_ds, synthetic_gptneo_100_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gptneo_100_ds, emotion_test_ds, \"augmented_gptneo_100\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gptneo_100\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmDxTuuwHvFh"
      },
      "source": [
        "# train our model on the dataset augmented by GPT-Neo that contains 200 extra synthetic samples.\n",
        "augmented_gptneo_200_ds = concatenate_datasets([emotion_train_ds, synthetic_gptneo_200_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gptneo_200_ds, emotion_test_ds, \"augmented_gptneo_200\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gptneo_200\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hFLaimXfRwn"
      },
      "source": [
        "##  üìä Visualize\n",
        "\n",
        "To evaluate the effectiveness of text augmentation in the performance of the model, we'll visualize the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XWA9lDzFWqG"
      },
      "source": [
        "### Model Performance\n",
        "\n",
        "Now let's compare the performance of the trained models. First, we will examine the accuracy improvements of text augmentation using GPT-3, GPT-J and GPT-Neo and then we will compare the three methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ROh9zOSfMwE"
      },
      "source": [
        "df = pd.DataFrame(run_dicts)\n",
        "\n",
        "gpt3_names = ['augmented_gpt3_10', 'augmented_gpt3_50', 'augmented_gpt3_100', 'augmented_gpt3_200']\n",
        "gptj_names = ['augmented_gptj_10', 'augmented_gptj_50', 'augmented_gptj_100', 'augmented_gptj_200']\n",
        "gptneo_names = ['augmented_gptneo_10', 'augmented_gptneo_50', 'augmented_gptneo_100', 'augmented_gptneo_200']\n",
        "\n",
        "# define a dataframe for each LM\n",
        "df_baseline = df.loc[df['id'] == 'baseline']\n",
        "df_gpt3 = df.loc[df['id'].isin(gpt3_names)]\n",
        "df_gptj = df.loc[df['id'].isin(gptj_names)]\n",
        "df_gptneo = df.loc[df['id'].isin(gptneo_names)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfqoKAyJfWMf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "ecbf8e5c-6ebe-4d59-c95c-ac4d52c3b2d0"
      },
      "source": [
        "# plot accuracy curve of GPT-3\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                    x=list(range(0, steps, 20)),\n",
        "                    y=pd.DataFrame(df_baseline.loc[0]['logs']).dropna(subset=['eval_accuracy'])['eval_accuracy'],\n",
        "                    name='accuracy {}'.format('baseline')))\n",
        "\n",
        "for index, row in df_gpt3.iterrows():\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "                    x=list(range(0, steps, 20)),\n",
        "                    y=pd.DataFrame(row['logs']).dropna(subset=['eval_accuracy'])['eval_accuracy'],\n",
        "                    name='accuracy {}'.format(row['id'])))\n",
        "\n",
        "fig.update_xaxes(title_text='step')\n",
        "fig.update_yaxes(title_text='accuracy')\n",
        "fig.update_layout(\n",
        "    title=\"Accuracy of the model in different versions of the dataset (augmentation by GPT-3).\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"cf1a7cf8-325b-4966-b1a9-7ed157477d23\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"cf1a7cf8-325b-4966-b1a9-7ed157477d23\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'cf1a7cf8-325b-4966-b1a9-7ed157477d23',\n",
              "                        [{\"name\": \"accuracy baseline\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.45294855708908405, 0.3324968632371393, 0.38017565872020076, 0.397741530740276, 0.4002509410288582, 0.4015056461731493, 0.4015056461731493]}, {\"name\": \"accuracy augmented_gpt3_10\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.4203262233375157, 0.5420326223337516, 0.5721455457967378, 0.5784190715181933, 0.5821831869510665, 0.5834378920953576, 0.5834378920953576]}, {\"name\": \"accuracy augmented_gpt3_50\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.45294855708908405, 0.4918444165621079, 0.5947302383939774, 0.5106649937264742, 0.5734002509410289, 0.5846925972396487, 0.5846925972396487]}, {\"name\": \"accuracy augmented_gpt3_100\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.26348808030112925, 0.7427854454203262, 0.8117942283563363, 0.6976160602258469, 0.616060225846926, 0.6612296110414053, 0.6637390213299874]}, {\"name\": \"accuracy augmented_gpt3_200\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.5181932245922208, 0.7590966122961104, 0.7089084065244667, 0.821831869510665, 0.7590966122961104, 0.7239648682559598, 0.71267252195734]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy of the model in different versions of the dataset (augmentation by GPT-3).\"}, \"xaxis\": {\"title\": {\"text\": \"step\"}}, \"yaxis\": {\"title\": {\"text\": \"accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cf1a7cf8-325b-4966-b1a9-7ed157477d23');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICRTJSC6SzZD"
      },
      "source": [
        "We observe that the accuracy of the model increases as we augment more and more data. After generating 200 extra synthetic samples, the accuracy exceeds 70% indicating that text augmentation can greatly improve the accuracy of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "iH90XkBgbcJj",
        "outputId": "2399761d-5573-497c-d29c-6c04de566481"
      },
      "source": [
        "# plot accuracy curve of GPT-J\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                    x=list(range(0, steps, 20)),\n",
        "                    y=pd.DataFrame(df_baseline.loc[0]['logs']).dropna(subset=['eval_accuracy'])['eval_accuracy'],\n",
        "                    name='accuracy {}'.format('baseline')))\n",
        "\n",
        "for index, row in df_gptj.iterrows():\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "                    x=list(range(0, steps, 20)),\n",
        "                    y=pd.DataFrame(row['logs']).dropna(subset=['eval_accuracy'])['eval_accuracy'],\n",
        "                    name='accuracy {}'.format(row['id'])))\n",
        "\n",
        "fig.update_xaxes(title_text='step')\n",
        "fig.update_yaxes(title_text='accuracy')\n",
        "fig.update_layout(\n",
        "    title=\"Accuracy of the model in different versions of the dataset (augmentation by GPT-J).\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"a1c5e95b-f151-4952-a38f-4c2b00e5482f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"a1c5e95b-f151-4952-a38f-4c2b00e5482f\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'a1c5e95b-f151-4952-a38f-4c2b00e5482f',\n",
              "                        [{\"name\": \"accuracy baseline\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.45294855708908405, 0.3324968632371393, 0.38017565872020076, 0.397741530740276, 0.4002509410288582, 0.4015056461731493, 0.4015056461731493]}, {\"name\": \"accuracy augmented_gptj_10\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.5370138017565872, 0.5821831869510665, 0.4730238393977415, 0.5006273525721455, 0.5131744040150564, 0.5181932245922208, 0.5194479297365119]}, {\"name\": \"accuracy augmented_gptj_50\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.7841907151819323, 0.7867001254705144, 0.6775407779171895, 0.7189460476787954, 0.6248431618569636, 0.671267252195734, 0.6775407779171895]}, {\"name\": \"accuracy augmented_gptj_100\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.7214554579673776, 0.8055207026348808, 0.8042659974905897, 0.7653701380175659, 0.7478042659974906, 0.7565872020075283, 0.7603513174404015]}, {\"name\": \"accuracy augmented_gptj_200\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.6750313676286073, 0.8092848180677541, 0.823086574654956, 0.8469259723964868, 0.8644918444165621, 0.8569636135508155, 0.8569636135508155]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy of the model in different versions of the dataset (augmentation by GPT-J).\"}, \"xaxis\": {\"title\": {\"text\": \"step\"}}, \"yaxis\": {\"title\": {\"text\": \"accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a1c5e95b-f151-4952-a38f-4c2b00e5482f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vhGv3G3TirU"
      },
      "source": [
        "The performance curve of GPT-J is awesome üéâ. Each time we increase the size of the train dataset with augmentation, there is a consistent increase in the accuracy reaching 85%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "5SvlbstrJBtg",
        "outputId": "139fe40e-34a3-4e9b-95e6-53c46d2949ce"
      },
      "source": [
        "# plot accuracy curve of GPT-Neo\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                    x=list(range(0, steps, 20)),\n",
        "                    y=pd.DataFrame(df_baseline.loc[0]['logs']).dropna(subset=['eval_accuracy'])['eval_accuracy'],\n",
        "                    name='accuracy {}'.format('baseline')))\n",
        "\n",
        "for index, row in df_gptneo.iterrows():\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "                    x=list(range(0, steps, 20)),\n",
        "                    y=pd.DataFrame(row['logs']).dropna(subset=['eval_accuracy'])['eval_accuracy'],\n",
        "                    name='accuracy {}'.format(row['id'])))\n",
        "\n",
        "fig.update_xaxes(title_text='step')\n",
        "fig.update_yaxes(title_text='accuracy')\n",
        "fig.update_layout(\n",
        "    title=\"Accuracy of the model in different versions of the dataset (augmentation by GPT-neo).\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"0423ff98-b418-4232-a88f-23d8fdf6b5c0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"0423ff98-b418-4232-a88f-23d8fdf6b5c0\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '0423ff98-b418-4232-a88f-23d8fdf6b5c0',\n",
              "                        [{\"name\": \"accuracy baseline\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.45294855708908405, 0.3324968632371393, 0.38017565872020076, 0.397741530740276, 0.4002509410288582, 0.4015056461731493, 0.4015056461731493]}, {\"name\": \"accuracy augmented_gptneo_10\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.39021329987452946, 0.36386449184441655, 0.35131744040150564, 0.36386449184441655, 0.36762860727728985, 0.370138017565872, 0.370138017565872]}, {\"name\": \"accuracy augmented_gptneo_50\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.2120451693851945, 0.4353826850690088, 0.562107904642409, 0.5018820577164367, 0.6010037641154329, 0.5846925972396487, 0.5859473023839398]}, {\"name\": \"accuracy augmented_gptneo_100\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.06273525721455459, 0.2860727728983689, 0.26348808030112925, 0.33751568381430364, 0.4215809284818068, 0.3212045169385194, 0.3324968632371393]}, {\"name\": \"accuracy augmented_gptneo_200\", \"type\": \"scatter\", \"x\": [0, 20, 40, 60, 80, 100, 120], \"y\": [0.06273525721455459, 0.07904642409033877, 0.27603513174404015, 0.21957340025094102, 0.48180677540777916, 0.39272271016311167, 0.39397741530740277]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy of the model in different versions of the dataset (augmentation by GPT-neo).\"}, \"xaxis\": {\"title\": {\"text\": \"step\"}}, \"yaxis\": {\"title\": {\"text\": \"accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0423ff98-b418-4232-a88f-23d8fdf6b5c0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c74rUyB3UDOo"
      },
      "source": [
        "The results of GPT-Neo are worse üòû. The performance of the model decreases when we generate synthetic data (except in the case of 50 synthetic samples)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjnV-ZHyCvMF"
      },
      "source": [
        "The next step is to investigate which language model boosts the final performance more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "xHliv6hLd_y2",
        "outputId": "9b71a72d-a9ce-4c8f-d81b-7146e49592ed"
      },
      "source": [
        "# keep the accuracy of the last training step\n",
        "acc_gpt3 = [df_baseline.iloc[0]['logs'][-1]['eval_accuracy']]\n",
        "for i in range(4):\n",
        "  acc_gpt3.append(df_gpt3.iloc[i]['logs'][-1]['eval_accuracy'])\n",
        "\n",
        "acc_gptj = [df_baseline.iloc[0]['logs'][-1]['eval_accuracy']]\n",
        "for i in range(4):\n",
        "  acc_gptj.append(df_gptj.iloc[i]['logs'][-1]['eval_accuracy'])\n",
        "\n",
        "acc_gptneo = [df_baseline.iloc[0]['logs'][-1]['eval_accuracy']]\n",
        "for i in range(4):\n",
        "  acc_gptneo.append(df_gptneo.iloc[i]['logs'][-1]['eval_accuracy'])\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                x=[0, 10, 50, 100, 200],\n",
        "                y=acc_gpt3,\n",
        "                name='GPT-3'))\n",
        "\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                x=[0, 10, 50, 100, 200],\n",
        "                y=acc_gptj,\n",
        "                name='GPT-J'))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                x=[0, 10, 50, 100, 200],\n",
        "                y=acc_gptneo,\n",
        "                name='GPT-Neo'))\n",
        "\n",
        "fig.update_xaxes(title_text='number of synthetic samples')\n",
        "fig.update_yaxes(title_text='accuracy')\n",
        "fig.update_layout(\n",
        "    title=\"Comparison of GPT-3, GPT-J and GPT-Neo in text augmentation.\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"cfebc7cc-5ed5-4ded-8b5b-1778ffdf8165\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"cfebc7cc-5ed5-4ded-8b5b-1778ffdf8165\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'cfebc7cc-5ed5-4ded-8b5b-1778ffdf8165',\n",
              "                        [{\"name\": \"GPT-3\", \"type\": \"scatter\", \"x\": [0, 10, 50, 100, 200], \"y\": [0.4015056461731493, 0.5834378920953576, 0.5846925972396487, 0.6637390213299874, 0.71267252195734]}, {\"name\": \"GPT-J\", \"type\": \"scatter\", \"x\": [0, 10, 50, 100, 200], \"y\": [0.4015056461731493, 0.5194479297365119, 0.6775407779171895, 0.7603513174404015, 0.8569636135508155]}, {\"name\": \"GPT-Neo\", \"type\": \"scatter\", \"x\": [0, 10, 50, 100, 200], \"y\": [0.4015056461731493, 0.370138017565872, 0.5859473023839398, 0.3324968632371393, 0.39397741530740277]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Comparison of GPT-3, GPT-J and GPT-Neo in text augmentation.\"}, \"xaxis\": {\"title\": {\"text\": \"number of synthetic samples\"}}, \"yaxis\": {\"title\": {\"text\": \"accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cfebc7cc-5ed5-4ded-8b5b-1778ffdf8165');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3KM1Y0DC9l_"
      },
      "source": [
        "GPT-J outperforms GPT-3 in almost all different versions of the dataset üëè. These are very exciting results that indicate that we can use the open-source GPT-J instead of GPT-3 for augmentation. As for the GPT-Neo, it performs very poorly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49PkQsXLipqi"
      },
      "source": [
        "### Label Distribution\n",
        "\n",
        "It is interesting to examine how the distribution of the labels changes when we generate more and more synthetic samples. Our initial train set is balanced since it consists of 10 samples per class. Let's see how the distribution of the labels changes after text augmentation! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Zv0UIqfM8Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "bf831046-717c-48d6-c8c0-3054817af0d7"
      },
      "source": [
        "fig = make_subplots(rows=1, cols=4,\n",
        "                    subplot_titles=(\"Baseline\", \"Augmented-GPT3-200\", \"Augmented-GPTJ-200\", \"Augmented-GPTneo-200\"))\n",
        "\n",
        "trace0 = go.Histogram(x=[idx2label[i] for i in emotion_train_ds[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "trace1 = go.Histogram(x=[idx2label[i] for i in augmented_gpt3_200_ds[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "trace2 = go.Histogram(x=[idx2label[i] for i in augmented_gptj_200_ds[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "trace3 = go.Histogram(x=[idx2label[i] for i in augmented_gptneo_200_ds[\"label\"]],\n",
        "                   opacity=0.8)\n",
        "\n",
        "fig.append_trace(trace0, 1, 1)\n",
        "fig.append_trace(trace1, 1, 2)\n",
        "fig.append_trace(trace2, 1, 3)\n",
        "fig.append_trace(trace2, 1, 4)\n",
        "fig.update_layout(showlegend=False, title_text=\"Distribution of labels\", \n",
        "                  bargap=0.30)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"061f419e-ca6f-40e1-b9da-4f8b622484fd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"061f419e-ca6f-40e1-b9da-4f8b622484fd\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '061f419e-ca6f-40e1-b9da-4f8b622484fd',\n",
              "                        [{\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\"], \"xaxis\": \"x\", \"yaxis\": \"y\"}, {\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"surprise\", \"joy\", \"anger\", \"joy\", \"surprise\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"anger\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"surprise\", \"surprise\", \"anger\", \"joy\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"joy\", \"joy\", \"joy\", \"joy\", \"surprise\", \"anger\", \"joy\", \"anger\", \"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"joy\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"anger\", \"surprise\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"anger\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"surprise\", \"joy\", \"anger\", \"joy\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"joy\", \"anger\", \"anger\", \"anger\", \"joy\", \"surprise\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"surprise\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"surprise\", \"joy\", \"anger\", \"anger\", \"anger\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"surprise\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"anger\", \"surprise\", \"anger\", \"anger\"], \"xaxis\": \"x2\", \"yaxis\": \"y2\"}, {\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"surprise\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"surprise\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"surprise\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"surprise\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"surprise\", \"joy\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"joy\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"surprise\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"surprise\", \"joy\", \"joy\", \"joy\", \"joy\", \"surprise\", \"surprise\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\"], \"xaxis\": \"x3\", \"yaxis\": \"y3\"}, {\"opacity\": 0.8, \"type\": \"histogram\", \"x\": [\"surprise\", \"anger\", \"joy\", \"surprise\", \"surprise\", \"surprise\", \"joy\", \"surprise\", \"surprise\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"anger\", \"anger\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"surprise\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"surprise\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"surprise\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"surprise\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"surprise\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"joy\", \"anger\", \"surprise\", \"joy\", \"joy\", \"anger\", \"anger\", \"surprise\", \"joy\", \"surprise\", \"joy\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"surprise\", \"joy\", \"joy\", \"joy\", \"surprise\", \"joy\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"surprise\", \"joy\", \"surprise\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"joy\", \"surprise\", \"joy\", \"joy\", \"surprise\", \"anger\", \"surprise\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"surprise\", \"anger\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"anger\", \"anger\", \"joy\", \"joy\", \"anger\", \"anger\", \"anger\", \"anger\", \"joy\", \"joy\", \"joy\", \"anger\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"surprise\", \"joy\", \"joy\", \"joy\", \"joy\", \"surprise\", \"surprise\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\", \"joy\"], \"xaxis\": \"x4\", \"yaxis\": \"y4\"}],\n",
              "                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Baseline\", \"x\": 0.10625, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Augmented-GPT3-200\", \"x\": 0.36875, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Augmented-GPTJ-200\", \"x\": 0.6312500000000001, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Augmented-GPTneo-200\", \"x\": 0.89375, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"bargap\": 0.3, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Distribution of labels\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.2125]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.2625, 0.475]}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.525, 0.7375]}, \"xaxis4\": {\"anchor\": \"y4\", \"domain\": [0.7875, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0]}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.0, 1.0]}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('061f419e-ca6f-40e1-b9da-4f8b622484fd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yutzoQDb0B4J"
      },
      "source": [
        "We observe that the distribution changes a lot and the large augmented dataset is highly imbalanced üòØ! GPT-3 model generated too many samples labeled as 'anger' while GPT-J and GPT-Neo generated more samples labeled as 'joy'. The reason of this behavior is the datasets that these models are pre-trained on. GPT-J and GPT-Neo are trained on the same dataset and change the label distribution in a similar way.\n",
        "\n",
        "That's an interesting observation that we should further examine in the future! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCT49FJwzhB3"
      },
      "source": [
        "## ‚õè Generate more samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2tMLY7qI8SK"
      },
      "source": [
        "Text augmentation increased accuracy by a lot! The next step is to examine how much the accuracy improves when adding even more labelled samples. We expect that at some point, the accuracy curve stops increasing and stabilizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSTaVSOfiUOQ"
      },
      "source": [
        "# load the synthetic datasets with 300, 400 and 500 samples.\n",
        "# run this if the dataset has already been saved!\n",
        "\n",
        "max_size = 500\n",
        "steps = 5*int(max_size/batch_size) # 4 epochs in the large dataset\n",
        "\n",
        "synthetic_gpt3_300_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-3/300')\n",
        "synthetic_gpt3_400_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-3/400')\n",
        "synthetic_gpt3_500_ds = load_from_disk('./drive/MyDrive/text_augmentation/gpt-3/500')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhJoOjz9zgdn"
      },
      "source": [
        "# train our model on the augmented dataset that contains 300 extra synthetic samples.\n",
        "augmented_gpt3_300_ds = concatenate_datasets([emotion_train_ds, synthetic_gpt3_300_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gpt3_300_ds, emotion_test_ds, \"augmented_300\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gpt3_300\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzDOZzglznET"
      },
      "source": [
        "# train our model on the augmented dataset that contains 400 extra synthetic samples.\n",
        "augmented_gpt3_400_ds= concatenate_datasets([emotion_train_ds, synthetic_gpt3_400_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gpt3_400_ds, emotion_test_ds, \"augmented_400\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gpt3_400\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q5IQje3zniJ"
      },
      "source": [
        "# train our model on the augmented dataset that contains 500 extra synthetic samples.\n",
        "augmented_gpt3_500_ds = concatenate_datasets([emotion_train_ds, synthetic_gpt3_500_ds])\n",
        "metrics, logs = train_and_evaluate(augmented_gpt3_500_ds, emotion_test_ds, \"augmented_500\")\n",
        "\n",
        "run_dicts.append({\n",
        "    \"id\": \"augmented_gpt3_500\",\n",
        "    \"metrics\": metrics,\n",
        "    \"logs\": logs\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPWA5_9Cz5-7"
      },
      "source": [
        "df = pd.DataFrame(run_dicts)\n",
        "gpt3_names_more = ['augmented_gpt3_10', 'augmented_gpt3_50', 'augmented_gpt3_100', 'augmented_gpt3_200', \n",
        "              'augmented_gpt3_300', 'augmented_gpt3_400', 'augmented_gpt3_500']\n",
        "\n",
        "df_gpt3_more = df.loc[df['id'].isin(gpt3_names_more)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "qur5SW4CmGeH",
        "outputId": "65e988e1-460a-4c42-f21e-98385bcdb9d9"
      },
      "source": [
        "acc_gpt3_more = [df_baseline.iloc[0]['logs'][-1]['eval_accuracy']]\n",
        "for i in range(7):\n",
        "  acc_gpt3_more.append(df_gpt3_more.iloc[i]['logs'][-1]['eval_accuracy'])\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                x=[0, 10, 50, 100, 200, 300, 400, 500],\n",
        "                y=acc_gpt3_more,\n",
        "                name='GPT-3'))\n",
        "\n",
        "fig.update_xaxes(title_text='number of extra samples')\n",
        "fig.update_yaxes(title_text='accuracy')\n",
        "fig.update_layout(showlegend=True, \n",
        "    title=\"Accuracy of the model in different versions of the dataset (augmentation by GPT-3).\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"c48e280a-9a36-4fa4-9861-b23b81909a35\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"c48e280a-9a36-4fa4-9861-b23b81909a35\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'c48e280a-9a36-4fa4-9861-b23b81909a35',\n",
              "                        [{\"name\": \"GPT-3\", \"type\": \"scatter\", \"x\": [0, 10, 50, 100, 200, 300, 400, 500], \"y\": [0.4015056461731493, 0.5834378920953576, 0.5846925972396487, 0.6637390213299874, 0.71267252195734, 0.6900878293601004, 0.7189460476787954, 0.6386449184441656]}],\n",
              "                        {\"showlegend\": true, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy of the model in different versions of the dataset (augmentation by GPT-3).\"}, \"xaxis\": {\"title\": {\"text\": \"number of extra samples\"}}, \"yaxis\": {\"title\": {\"text\": \"accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c48e280a-9a36-4fa4-9861-b23b81909a35');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk_OM52qz-MV"
      },
      "source": [
        "The curve goes up really fast in the beginning but the increase gradually slows down the more samples we generate. So, we realise that there is a limit in the performance improvements that text augmentation can yield."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ALJ0WldXtrp"
      },
      "source": [
        "## üèÅ Take-aways \n",
        "\n",
        "\n",
        "You've reached the finish line! üëè  Let's sum up some of the findings.\n",
        "\n",
        "* We generated hyper-realistic synthetic samples by leveraging the few-shot capabilities of large LMs and prompt engineering.\n",
        "* As a baseline, we trained a distilbert model on the Emotion dataset using a small subset of 30 samples.\n",
        "* Then, we augmented the small dataset with 10, 50, 100 and 200 extra samples generated by GPT-3, GPT-J and GPT-Neo.\n",
        "* We compared the performance of the models in all these settings and showed that data augmentation boosts the performance ü•≥.\n",
        "* We showed that GPT-J performs better than GPT-3 in our task and can be used as an open-source alternative for text augmentation üí™. GPT-Neo performs poorly mainly because it is much smaller.\n",
        "* However, the augmented datasets are not balanced anymore because large LMs are prone to generate samples with certain labels based on the data they are trained on.\n",
        "* Finally, as we generate more and more synthetic samples and the size of the training set increases, the overall performance increases until some point. Then, text augmentation cannot improve the performance more and we should look into other ways of increasing performance.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}